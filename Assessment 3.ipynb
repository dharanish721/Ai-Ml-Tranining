{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9acab99c-2914-4119-97f8-bb081575b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "import logging\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "069a1e11-5cb5-46ab-9de6-eb4767debf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename='retail_etl.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df56cc01-25f2-4245-8f8d-47b0d6d7db62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 'data/' folder created. Please add CSVs inside it.\n"
     ]
    }
   ],
   "source": [
    "data_folder = 'data/'\n",
    "\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "    print(\"‚úÖ 'data/' folder created. Please add CSVs inside it.\")\n",
    "else:\n",
    "    print(\"üìÅ 'data/' folder already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bc1fadf-b63b-4928-a8ee-8a8f112991ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a248be0e-7f38-4f75-90c0-6c4384217368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ 'data/' folder already exists.\n",
      "‚úÖ Raw data combined:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "data_folder = 'data/'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "    print(\"‚úÖ 'data/' folder created. Add your CSV files into this folder.\")\n",
    "else:\n",
    "    print(\"üìÅ 'data/' folder already exists.\")\n",
    "\n",
    "# Combine all CSV files in the folder into a single DataFrame\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(data_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "        temp_df = pd.read_csv(file_path)\n",
    "        combined_df = pd.concat([combined_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"‚úÖ Raw data combined:\")\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d24ec8e2-4cc4-4c06-b78d-22001e218dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01733cc5-d28f-4580-b6d7-4bbced0c30ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Available columns after normalization:\n",
      "[]\n",
      "‚ùå Missing columns in the data: ['quantity_sold', 'unit_price', 'discount_percent', 'payment_mode', 'date', 'store_id', 'product_id', 'product_name']\n"
     ]
    }
   ],
   "source": [
    "combined_df.columns = [col.strip().lower().replace(' ', '_') for col in combined_df.columns]\n",
    "\n",
    "# üîç Step 1: Print available columns\n",
    "print(\"üìã Available columns after normalization:\")\n",
    "print(combined_df.columns.tolist())\n",
    "\n",
    "# ‚úÖ Step 2: Check if required columns exist before proceeding\n",
    "required_columns = ['quantity_sold', 'unit_price', 'discount_percent', 'payment_mode', 'date', 'store_id', 'product_id', 'product_name']\n",
    "\n",
    "missing_columns = [col for col in required_columns if col not in combined_df.columns]\n",
    "if missing_columns:\n",
    "    print(f\"‚ùå Missing columns in the data: {missing_columns}\")\n",
    "else:\n",
    "    # ‚úÖ Handle missing values\n",
    "    combined_df.fillna({\n",
    "        'quantity_sold': 0,\n",
    "        'unit_price': 0.0,\n",
    "        'discount_percent': 0.0,\n",
    "        'payment_mode': 'Unknown'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # ‚úÖ Calculate total sale value\n",
    "    combined_df['total_sale_value'] = (\n",
    "        combined_df['quantity_sold'] *\n",
    "        combined_df['unit_price'] *\n",
    "        (1 - combined_df['discount_percent'] / 100)\n",
    "    )\n",
    "\n",
    "    # ‚úÖ Convert 'date' column to datetime\n",
    "    combined_df['date'] = pd.to_datetime(combined_df['date'], errors='coerce')\n",
    "\n",
    "    # ‚úÖ Drop duplicates\n",
    "    combined_df.drop_duplicates(subset=['store_id', 'date', 'product_id'], inplace=True)\n",
    "\n",
    "    # ‚úÖ Categorize sales\n",
    "    combined_df['sale_category'] = np.where(\n",
    "        combined_df['total_sale_value'] >= 10000, 'High',\n",
    "        np.where(combined_df['total_sale_value'] >= 5000, 'Medium', 'Low')\n",
    "    )\n",
    "\n",
    "    # üëÄ Preview the cleaned data\n",
    "    print(\"‚úÖ Transformed DataFrame:\")\n",
    "    print(combined_df.head())\n",
    "    print(combined_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ec84cdd-d5b7-4447-b933-48ab269fd4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5f0b0d2-151e-409a-ab51-dce702285e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded into MySQL successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # ‚úÖ Connect to MySQL database (update credentials if needed)\n",
    "    mydb = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"Dharanish@07\",      # Update if you use a different password\n",
    "        database=\"retail\"     # Make sure this DB exists. Create manually if needed.\n",
    "    )\n",
    "\n",
    "    cursor = mydb.cursor()\n",
    "\n",
    "    # ‚úÖ Create table if not exists\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS retail_sales (\n",
    "            store_id VARCHAR(20),\n",
    "            date DATE,\n",
    "            product_id VARCHAR(20),\n",
    "            product_name VARCHAR(100),\n",
    "            quantity_sold INT,\n",
    "            unit_price FLOAT,\n",
    "            discount_percent FLOAT,\n",
    "            payment_mode VARCHAR(20),\n",
    "            total_sale_value FLOAT,\n",
    "            sale_category VARCHAR(20),\n",
    "            PRIMARY KEY (store_id, date, product_id)\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    # ‚úÖ Insert each row with ON DUPLICATE KEY UPDATE (idempotent insert)\n",
    "    for _, row in combined_df.iterrows():\n",
    "        sql = \"\"\"\n",
    "            INSERT INTO retail_sales (\n",
    "                store_id, date, product_id, product_name,\n",
    "                quantity_sold, unit_price, discount_percent,\n",
    "                payment_mode, total_sale_value, sale_category\n",
    "            )\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            ON DUPLICATE KEY UPDATE\n",
    "                quantity_sold=VALUES(quantity_sold),\n",
    "                unit_price=VALUES(unit_price),\n",
    "                discount_percent=VALUES(discount_percent),\n",
    "                payment_mode=VALUES(payment_mode),\n",
    "                total_sale_value=VALUES(total_sale_value),\n",
    "                sale_category=VALUES(sale_category)\n",
    "        \"\"\"\n",
    "        values = (\n",
    "            row['store_id'],\n",
    "            row['date'],\n",
    "            row['product_id'],\n",
    "            row['product_name'],\n",
    "            int(row['quantity_sold']),\n",
    "            float(row['unit_price']),\n",
    "            float(row['discount_percent']),\n",
    "            row['payment_mode'],\n",
    "            float(row['total_sale_value']),\n",
    "            row['sale_category']\n",
    "        )\n",
    "        cursor.execute(sql, values)\n",
    "\n",
    "    # ‚úÖ Commit and close\n",
    "    mydb.commit()\n",
    "    cursor.close()\n",
    "    mydb.close()\n",
    "\n",
    "    print(\"‚úÖ Data loaded into MySQL successfully.\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(\"‚ùå MySQL Error:\", err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943bc96-089b-44f8-a5e6-d6585d485162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
