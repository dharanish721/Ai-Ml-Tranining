{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a21a877e-a917-43b4-9ce8-926179072dc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"/Volumes/workspace/students/sampledata/sample_ml_data.csv\")\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df['Age'] = imputer.fit_transform(df[['Age']])\n",
    "df['Salary'] = imputer.fit_transform(df[['Salary']])\n",
    "df['Gender'] = df['Gender'].fillna(df['Gender'].mode()[0])\n",
    "\n",
    "# Encode categorical variables\n",
    "df_encoded = pd.get_dummies(df, columns=[\"Gender\"], drop_first=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_encoded[\"Purchased\"] = label_encoder.fit_transform(df_encoded[\"Purchased\"])\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "df_encoded[[\"Age\", \"Salary\"]] = scaler.fit_transform(df_encoded[[\"Age\", \"Salary\"]])\n",
    "\n",
    "# Split into train and test sets\n",
    "X = df_encoded.drop(\"Purchased\", axis=1)\n",
    "y = df_encoded[\"Purchased\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nCleaned and Preprocessed Data (Train):\")\n",
    "print(X_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "955921c1-1af9-43f3-ba53-0b07102144da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-6117612572702009>, line 28\u001B[0m\n",
       "\u001B[1;32m     22\u001B[0m pipeline \u001B[38;5;241m=\u001B[39m Pipeline([\n",
       "\u001B[1;32m     23\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscaler\u001B[39m\u001B[38;5;124m'\u001B[39m, StandardScaler()),\n",
       "\u001B[1;32m     24\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclassifier\u001B[39m\u001B[38;5;124m'\u001B[39m, RandomForestClassifier(random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m))\n",
       "\u001B[1;32m     25\u001B[0m ])\n",
       "\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# \uD83D\uDCCA Cross-Validation to assess performance\u001B[39;00m\n",
       "\u001B[0;32m---> 28\u001B[0m cv_scores \u001B[38;5;241m=\u001B[39m cross_val_score(pipeline, X_train, y_train, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, error_score\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[1;32m     29\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m✅ Cross-validation scores:\u001B[39m\u001B[38;5;124m\"\u001B[39m, cv_scores)\n",
       "\u001B[1;32m     30\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m✅ Average cross-validation accuracy:\u001B[39m\u001B[38;5;124m\"\u001B[39m, cv_scores\u001B[38;5;241m.\u001B[39mmean())\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:562\u001B[0m, in \u001B[0;36mcross_val_score\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n",
       "\u001B[1;32m    559\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n",
       "\u001B[1;32m    560\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n",
       "\u001B[0;32m--> 562\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m cross_validate(\n",
       "\u001B[1;32m    563\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mestimator,\n",
       "\u001B[1;32m    564\u001B[0m     X\u001B[38;5;241m=\u001B[39mX,\n",
       "\u001B[1;32m    565\u001B[0m     y\u001B[38;5;241m=\u001B[39my,\n",
       "\u001B[1;32m    566\u001B[0m     groups\u001B[38;5;241m=\u001B[39mgroups,\n",
       "\u001B[1;32m    567\u001B[0m     scoring\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m: scorer},\n",
       "\u001B[1;32m    568\u001B[0m     cv\u001B[38;5;241m=\u001B[39mcv,\n",
       "\u001B[1;32m    569\u001B[0m     n_jobs\u001B[38;5;241m=\u001B[39mn_jobs,\n",
       "\u001B[1;32m    570\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mverbose,\n",
       "\u001B[1;32m    571\u001B[0m     fit_params\u001B[38;5;241m=\u001B[39mfit_params,\n",
       "\u001B[1;32m    572\u001B[0m     pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch,\n",
       "\u001B[1;32m    573\u001B[0m     error_score\u001B[38;5;241m=\u001B[39merror_score,\n",
       "\u001B[1;32m    574\u001B[0m )\n",
       "\u001B[1;32m    575\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m    206\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n",
       "\u001B[1;32m    207\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n",
       "\u001B[1;32m    208\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n",
       "\u001B[1;32m    209\u001B[0m         )\n",
       "\u001B[1;32m    210\u001B[0m     ):\n",
       "\u001B[0;32m--> 211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    213\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n",
       "\u001B[1;32m    214\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n",
       "\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n",
       "\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n",
       "\u001B[1;32m    217\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n",
       "\u001B[1;32m    218\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    220\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n",
       "\u001B[1;32m    221\u001B[0m     )\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:309\u001B[0m, in \u001B[0;36mcross_validate\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001B[0m\n",
       "\u001B[1;32m    306\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n",
       "\u001B[1;32m    307\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n",
       "\u001B[1;32m    308\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n",
       "\u001B[0;32m--> 309\u001B[0m results \u001B[38;5;241m=\u001B[39m parallel(\n",
       "\u001B[1;32m    310\u001B[0m     delayed(_fit_and_score)(\n",
       "\u001B[1;32m    311\u001B[0m         clone(estimator),\n",
       "\u001B[1;32m    312\u001B[0m         X,\n",
       "\u001B[1;32m    313\u001B[0m         y,\n",
       "\u001B[1;32m    314\u001B[0m         scorers,\n",
       "\u001B[1;32m    315\u001B[0m         train,\n",
       "\u001B[1;32m    316\u001B[0m         test,\n",
       "\u001B[1;32m    317\u001B[0m         verbose,\n",
       "\u001B[1;32m    318\u001B[0m         \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m    319\u001B[0m         fit_params,\n",
       "\u001B[1;32m    320\u001B[0m         return_train_score\u001B[38;5;241m=\u001B[39mreturn_train_score,\n",
       "\u001B[1;32m    321\u001B[0m         return_times\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n",
       "\u001B[1;32m    322\u001B[0m         return_estimator\u001B[38;5;241m=\u001B[39mreturn_estimator,\n",
       "\u001B[1;32m    323\u001B[0m         error_score\u001B[38;5;241m=\u001B[39merror_score,\n",
       "\u001B[1;32m    324\u001B[0m     )\n",
       "\u001B[1;32m    325\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m indices\n",
       "\u001B[1;32m    326\u001B[0m )\n",
       "\u001B[1;32m    328\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n",
       "\u001B[1;32m    330\u001B[0m \u001B[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001B[39;00m\n",
       "\u001B[1;32m    331\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n",
       "\u001B[1;32m    332\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n",
       "\u001B[1;32m     60\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n",
       "\u001B[1;32m     61\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n",
       "\u001B[1;32m     62\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n",
       "\u001B[1;32m     63\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n",
       "\u001B[1;32m     64\u001B[0m )\n",
       "\u001B[0;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(iterable_with_config)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/joblib/parallel.py:1085\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n",
       "\u001B[1;32m   1076\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m   1077\u001B[0m     \u001B[38;5;66;03m# Only set self._iterating to True if at least a batch\u001B[39;00m\n",
       "\u001B[1;32m   1078\u001B[0m     \u001B[38;5;66;03m# was dispatched. In particular this covers the edge\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   1082\u001B[0m     \u001B[38;5;66;03m# was very quick and its callback already dispatched all the\u001B[39;00m\n",
       "\u001B[1;32m   1083\u001B[0m     \u001B[38;5;66;03m# remaining jobs.\u001B[39;00m\n",
       "\u001B[1;32m   1084\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\u001B[0;32m-> 1085\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n",
       "\u001B[1;32m   1086\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m   1088\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/joblib/parallel.py:901\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n",
       "\u001B[1;32m    899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\u001B[1;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 901\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dispatch(tasks)\n",
       "\u001B[1;32m    902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/joblib/parallel.py:819\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[0;34m(self, batch)\u001B[0m\n",
       "\u001B[1;32m    817\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
       "\u001B[1;32m    818\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n",
       "\u001B[0;32m--> 819\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mapply_async(batch, callback\u001B[38;5;241m=\u001B[39mcb)\n",
       "\u001B[1;32m    820\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n",
       "\u001B[1;32m    821\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n",
       "\u001B[1;32m    822\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n",
       "\u001B[1;32m    823\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n",
       "\u001B[1;32m    824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[0;34m(self, func, callback)\u001B[0m\n",
       "\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n",
       "\u001B[1;32m    207\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n",
       "\u001B[0;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m ImmediateResult(func)\n",
       "\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n",
       "\u001B[1;32m    210\u001B[0m         callback(result)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[0;34m(self, batch)\u001B[0m\n",
       "\u001B[1;32m    594\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n",
       "\u001B[1;32m    595\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n",
       "\u001B[1;32m    596\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n",
       "\u001B[0;32m--> 597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m batch()\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n",
       "\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n",
       "\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n",
       "\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n",
       "\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n",
       "\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n",
       "\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n",
       "\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n",
       "\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n",
       "\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    125\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n",
       "\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n",
       "\u001B[0;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:732\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n",
       "\u001B[1;32m    730\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n",
       "\u001B[1;32m    731\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 732\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n",
       "\u001B[1;32m    734\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n",
       "\u001B[1;32m    735\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n",
       "\u001B[1;32m    736\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29\u001B[0m, in \u001B[0;36m_create_patch_function.<locals>.patch_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m     28\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\u001B[0;32m---> 29\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m     30\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n",
       "\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n",
       "\u001B[1;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n",
       "\u001B[1;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n",
       "\u001B[1;32m   1149\u001B[0m     )\n",
       "\u001B[1;32m   1150\u001B[0m ):\n",
       "\u001B[0;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/pipeline.py:420\u001B[0m, in \u001B[0;36mPipeline.fit\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n",
       "\u001B[1;32m    418\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
       "\u001B[1;32m    419\u001B[0m         fit_params_last_step \u001B[38;5;241m=\u001B[39m fit_params_steps[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m0\u001B[39m]]\n",
       "\u001B[0;32m--> 420\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator\u001B[38;5;241m.\u001B[39mfit(Xt, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params_last_step)\n",
       "\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29\u001B[0m, in \u001B[0;36m_create_patch_function.<locals>.patch_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[1;32m     28\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
       "\u001B[0;32m---> 29\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m     30\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n",
       "\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n",
       "\u001B[1;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n",
       "\u001B[1;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n",
       "\u001B[1;32m   1149\u001B[0m     )\n",
       "\u001B[1;32m   1150\u001B[0m ):\n",
       "\u001B[0;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:348\u001B[0m, in \u001B[0;36mBaseForest.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n",
       "\u001B[1;32m    346\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(y):\n",
       "\u001B[1;32m    347\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse multilabel-indicator for y is not supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[0;32m--> 348\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(\n",
       "\u001B[1;32m    349\u001B[0m     X, y, multi_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsc\u001B[39m\u001B[38;5;124m\"\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mDTYPE\n",
       "\u001B[1;32m    350\u001B[0m )\n",
       "\u001B[1;32m    351\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m    352\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m _check_sample_weight(sample_weight, X)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/base.py:621\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n",
       "\u001B[1;32m    619\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n",
       "\u001B[1;32m    620\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 621\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m check_X_y(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n",
       "\u001B[1;32m    622\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n",
       "\u001B[1;32m    624\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/validation.py:1147\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n",
       "\u001B[1;32m   1142\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n",
       "\u001B[1;32m   1143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m   1144\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1145\u001B[0m     )\n",
       "\u001B[0;32m-> 1147\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n",
       "\u001B[1;32m   1148\u001B[0m     X,\n",
       "\u001B[1;32m   1149\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n",
       "\u001B[1;32m   1150\u001B[0m     accept_large_sparse\u001B[38;5;241m=\u001B[39maccept_large_sparse,\n",
       "\u001B[1;32m   1151\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n",
       "\u001B[1;32m   1152\u001B[0m     order\u001B[38;5;241m=\u001B[39morder,\n",
       "\u001B[1;32m   1153\u001B[0m     copy\u001B[38;5;241m=\u001B[39mcopy,\n",
       "\u001B[1;32m   1154\u001B[0m     force_all_finite\u001B[38;5;241m=\u001B[39mforce_all_finite,\n",
       "\u001B[1;32m   1155\u001B[0m     ensure_2d\u001B[38;5;241m=\u001B[39mensure_2d,\n",
       "\u001B[1;32m   1156\u001B[0m     allow_nd\u001B[38;5;241m=\u001B[39mallow_nd,\n",
       "\u001B[1;32m   1157\u001B[0m     ensure_min_samples\u001B[38;5;241m=\u001B[39mensure_min_samples,\n",
       "\u001B[1;32m   1158\u001B[0m     ensure_min_features\u001B[38;5;241m=\u001B[39mensure_min_features,\n",
       "\u001B[1;32m   1159\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mestimator,\n",
       "\u001B[1;32m   1160\u001B[0m     input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m   1161\u001B[0m )\n",
       "\u001B[1;32m   1163\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n",
       "\u001B[1;32m   1165\u001B[0m check_consistent_length(X, y)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/validation.py:959\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n",
       "\u001B[1;32m    953\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    954\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    955\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n",
       "\u001B[1;32m    956\u001B[0m         )\n",
       "\u001B[1;32m    958\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n",
       "\u001B[0;32m--> 959\u001B[0m         _assert_all_finite(\n",
       "\u001B[1;32m    960\u001B[0m             array,\n",
       "\u001B[1;32m    961\u001B[0m             input_name\u001B[38;5;241m=\u001B[39minput_name,\n",
       "\u001B[1;32m    962\u001B[0m             estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n",
       "\u001B[1;32m    963\u001B[0m             allow_nan\u001B[38;5;241m=\u001B[39mforce_all_finite \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    964\u001B[0m         )\n",
       "\u001B[1;32m    966\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\u001B[1;32m    967\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/validation.py:124\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n",
       "\u001B[1;32m    121\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first_pass_isfinite:\n",
       "\u001B[1;32m    122\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n",
       "\u001B[0;32m--> 124\u001B[0m _assert_all_finite_element_wise(\n",
       "\u001B[1;32m    125\u001B[0m     X,\n",
       "\u001B[1;32m    126\u001B[0m     xp\u001B[38;5;241m=\u001B[39mxp,\n",
       "\u001B[1;32m    127\u001B[0m     allow_nan\u001B[38;5;241m=\u001B[39mallow_nan,\n",
       "\u001B[1;32m    128\u001B[0m     msg_dtype\u001B[38;5;241m=\u001B[39mmsg_dtype,\n",
       "\u001B[1;32m    129\u001B[0m     estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n",
       "\u001B[1;32m    130\u001B[0m     input_name\u001B[38;5;241m=\u001B[39minput_name,\n",
       "\u001B[1;32m    131\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/validation.py:173\u001B[0m, in \u001B[0;36m_assert_all_finite_element_wise\u001B[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n",
       "\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n",
       "\u001B[1;32m    157\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n",
       "\u001B[1;32m    158\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n",
       "\u001B[1;32m    159\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n",
       "\u001B[1;32m    160\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    161\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    171\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    172\u001B[0m     )\n",
       "\u001B[0;32m--> 173\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: Input X contains NaN.\n",
       "RandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ValueError",
        "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ValueError</span>: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
        "File \u001B[0;32m<command-6117612572702009>, line 28\u001B[0m\n\u001B[1;32m     22\u001B[0m pipeline \u001B[38;5;241m=\u001B[39m Pipeline([\n\u001B[1;32m     23\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscaler\u001B[39m\u001B[38;5;124m'\u001B[39m, StandardScaler()),\n\u001B[1;32m     24\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclassifier\u001B[39m\u001B[38;5;124m'\u001B[39m, RandomForestClassifier(random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m))\n\u001B[1;32m     25\u001B[0m ])\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# \uD83D\uDCCA Cross-Validation to assess performance\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m cv_scores \u001B[38;5;241m=\u001B[39m cross_val_score(pipeline, X_train, y_train, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, error_score\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m✅ Cross-validation scores:\u001B[39m\u001B[38;5;124m\"\u001B[39m, cv_scores)\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m✅ Average cross-validation accuracy:\u001B[39m\u001B[38;5;124m\"\u001B[39m, cv_scores\u001B[38;5;241m.\u001B[39mmean())\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:562\u001B[0m, in \u001B[0;36mcross_val_score\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001B[0m\n\u001B[1;32m    559\u001B[0m \u001B[38;5;66;03m# To ensure multimetric format is not supported\u001B[39;00m\n\u001B[1;32m    560\u001B[0m scorer \u001B[38;5;241m=\u001B[39m check_scoring(estimator, scoring\u001B[38;5;241m=\u001B[39mscoring)\n\u001B[0;32m--> 562\u001B[0m cv_results \u001B[38;5;241m=\u001B[39m cross_validate(\n\u001B[1;32m    563\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mestimator,\n\u001B[1;32m    564\u001B[0m     X\u001B[38;5;241m=\u001B[39mX,\n\u001B[1;32m    565\u001B[0m     y\u001B[38;5;241m=\u001B[39my,\n\u001B[1;32m    566\u001B[0m     groups\u001B[38;5;241m=\u001B[39mgroups,\n\u001B[1;32m    567\u001B[0m     scoring\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m: scorer},\n\u001B[1;32m    568\u001B[0m     cv\u001B[38;5;241m=\u001B[39mcv,\n\u001B[1;32m    569\u001B[0m     n_jobs\u001B[38;5;241m=\u001B[39mn_jobs,\n\u001B[1;32m    570\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[1;32m    571\u001B[0m     fit_params\u001B[38;5;241m=\u001B[39mfit_params,\n\u001B[1;32m    572\u001B[0m     pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch,\n\u001B[1;32m    573\u001B[0m     error_score\u001B[38;5;241m=\u001B[39merror_score,\n\u001B[1;32m    574\u001B[0m )\n\u001B[1;32m    575\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cv_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_score\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    207\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    208\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    209\u001B[0m         )\n\u001B[1;32m    210\u001B[0m     ):\n\u001B[0;32m--> 211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    213\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    220\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    221\u001B[0m     )\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:309\u001B[0m, in \u001B[0;36mcross_validate\u001B[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001B[0m\n\u001B[1;32m    306\u001B[0m \u001B[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001B[39;00m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;66;03m# independent, and that it is pickle-able.\u001B[39;00m\n\u001B[1;32m    308\u001B[0m parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39mverbose, pre_dispatch\u001B[38;5;241m=\u001B[39mpre_dispatch)\n\u001B[0;32m--> 309\u001B[0m results \u001B[38;5;241m=\u001B[39m parallel(\n\u001B[1;32m    310\u001B[0m     delayed(_fit_and_score)(\n\u001B[1;32m    311\u001B[0m         clone(estimator),\n\u001B[1;32m    312\u001B[0m         X,\n\u001B[1;32m    313\u001B[0m         y,\n\u001B[1;32m    314\u001B[0m         scorers,\n\u001B[1;32m    315\u001B[0m         train,\n\u001B[1;32m    316\u001B[0m         test,\n\u001B[1;32m    317\u001B[0m         verbose,\n\u001B[1;32m    318\u001B[0m         \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    319\u001B[0m         fit_params,\n\u001B[1;32m    320\u001B[0m         return_train_score\u001B[38;5;241m=\u001B[39mreturn_train_score,\n\u001B[1;32m    321\u001B[0m         return_times\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    322\u001B[0m         return_estimator\u001B[38;5;241m=\u001B[39mreturn_estimator,\n\u001B[1;32m    323\u001B[0m         error_score\u001B[38;5;241m=\u001B[39merror_score,\n\u001B[1;32m    324\u001B[0m     )\n\u001B[1;32m    325\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m indices\n\u001B[1;32m    326\u001B[0m )\n\u001B[1;32m    328\u001B[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001B[1;32m    330\u001B[0m \u001B[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001B[39;00m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001B[39;00m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;66;03m# the correct key.\u001B[39;00m\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     60\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     61\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     62\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     64\u001B[0m )\n\u001B[0;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(iterable_with_config)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/joblib/parallel.py:1085\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1076\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1077\u001B[0m     \u001B[38;5;66;03m# Only set self._iterating to True if at least a batch\u001B[39;00m\n\u001B[1;32m   1078\u001B[0m     \u001B[38;5;66;03m# was dispatched. In particular this covers the edge\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1082\u001B[0m     \u001B[38;5;66;03m# was very quick and its callback already dispatched all the\u001B[39;00m\n\u001B[1;32m   1083\u001B[0m     \u001B[38;5;66;03m# remaining jobs.\u001B[39;00m\n\u001B[1;32m   1084\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m-> 1085\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[1;32m   1086\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1088\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/joblib/parallel.py:901\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 901\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dispatch(tasks)\n\u001B[1;32m    902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/joblib/parallel.py:819\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    817\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    818\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[0;32m--> 819\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mapply_async(batch, callback\u001B[38;5;241m=\u001B[39mcb)\n\u001B[1;32m    820\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[1;32m    821\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[1;32m    822\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[1;32m    823\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[1;32m    824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    207\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[0;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m ImmediateResult(func)\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[1;32m    210\u001B[0m         callback(result)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    594\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[1;32m    595\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[1;32m    596\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[0;32m--> 597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m batch()\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    125\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[0;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:732\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    730\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m    731\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 732\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m    734\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m    735\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[1;32m    736\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29\u001B[0m, in \u001B[0;36m_create_patch_function.<locals>.patch_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     28\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     30\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1149\u001B[0m     )\n\u001B[1;32m   1150\u001B[0m ):\n\u001B[0;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/pipeline.py:420\u001B[0m, in \u001B[0;36mPipeline.fit\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m    418\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpassthrough\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    419\u001B[0m         fit_params_last_step \u001B[38;5;241m=\u001B[39m fit_params_steps[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m0\u001B[39m]]\n\u001B[0;32m--> 420\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_final_estimator\u001B[38;5;241m.\u001B[39mfit(Xt, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params_last_step)\n\u001B[1;32m    422\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29\u001B[0m, in \u001B[0;36m_create_patch_function.<locals>.patch_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     28\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m     original_result \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     30\u001B[0m     original_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m original_result\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1149\u001B[0m     )\n\u001B[1;32m   1150\u001B[0m ):\n\u001B[0;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:348\u001B[0m, in \u001B[0;36mBaseForest.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(y):\n\u001B[1;32m    347\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse multilabel-indicator for y is not supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 348\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(\n\u001B[1;32m    349\u001B[0m     X, y, multi_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsc\u001B[39m\u001B[38;5;124m\"\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mDTYPE\n\u001B[1;32m    350\u001B[0m )\n\u001B[1;32m    351\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    352\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m _check_sample_weight(sample_weight, X)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/base.py:621\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[1;32m    619\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[1;32m    620\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 621\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m check_X_y(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[1;32m    622\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    624\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/validation.py:1147\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m   1142\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[1;32m   1143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1144\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1145\u001B[0m     )\n\u001B[0;32m-> 1147\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[1;32m   1148\u001B[0m     X,\n\u001B[1;32m   1149\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[1;32m   1150\u001B[0m     accept_large_sparse\u001B[38;5;241m=\u001B[39maccept_large_sparse,\n\u001B[1;32m   1151\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[1;32m   1152\u001B[0m     order\u001B[38;5;241m=\u001B[39morder,\n\u001B[1;32m   1153\u001B[0m     copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[1;32m   1154\u001B[0m     force_all_finite\u001B[38;5;241m=\u001B[39mforce_all_finite,\n\u001B[1;32m   1155\u001B[0m     ensure_2d\u001B[38;5;241m=\u001B[39mensure_2d,\n\u001B[1;32m   1156\u001B[0m     allow_nd\u001B[38;5;241m=\u001B[39mallow_nd,\n\u001B[1;32m   1157\u001B[0m     ensure_min_samples\u001B[38;5;241m=\u001B[39mensure_min_samples,\n\u001B[1;32m   1158\u001B[0m     ensure_min_features\u001B[38;5;241m=\u001B[39mensure_min_features,\n\u001B[1;32m   1159\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mestimator,\n\u001B[1;32m   1160\u001B[0m     input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1161\u001B[0m )\n\u001B[1;32m   1163\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[1;32m   1165\u001B[0m check_consistent_length(X, y)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/validation.py:959\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    953\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    954\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    955\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[1;32m    956\u001B[0m         )\n\u001B[1;32m    958\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[0;32m--> 959\u001B[0m         _assert_all_finite(\n\u001B[1;32m    960\u001B[0m             array,\n\u001B[1;32m    961\u001B[0m             input_name\u001B[38;5;241m=\u001B[39minput_name,\n\u001B[1;32m    962\u001B[0m             estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n\u001B[1;32m    963\u001B[0m             allow_nan\u001B[38;5;241m=\u001B[39mforce_all_finite \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    964\u001B[0m         )\n\u001B[1;32m    966\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    967\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/validation.py:124\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first_pass_isfinite:\n\u001B[1;32m    122\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m--> 124\u001B[0m _assert_all_finite_element_wise(\n\u001B[1;32m    125\u001B[0m     X,\n\u001B[1;32m    126\u001B[0m     xp\u001B[38;5;241m=\u001B[39mxp,\n\u001B[1;32m    127\u001B[0m     allow_nan\u001B[38;5;241m=\u001B[39mallow_nan,\n\u001B[1;32m    128\u001B[0m     msg_dtype\u001B[38;5;241m=\u001B[39mmsg_dtype,\n\u001B[1;32m    129\u001B[0m     estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n\u001B[1;32m    130\u001B[0m     input_name\u001B[38;5;241m=\u001B[39minput_name,\n\u001B[1;32m    131\u001B[0m )\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/sklearn/utils/validation.py:173\u001B[0m, in \u001B[0;36m_assert_all_finite_element_wise\u001B[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[1;32m    157\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[1;32m    158\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[1;32m    159\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    160\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    161\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    171\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    172\u001B[0m     )\n\u001B[0;32m--> 173\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
        "\u001B[0;31mValueError\u001B[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# \uD83D\uDCC2 Load your dataset\n",
    "df = pd.read_csv(\"/Volumes/workspace/students/sampledata/sample_ml_data.csv\")  # Replace with the file you are using\n",
    "\n",
    "# \uD83C\uDFAF Prepare Features (X) and Target (y)\n",
    "X = df.iloc[:, :-1]   # All columns except last\n",
    "y = df.iloc[:, -1]    # Last column as target\n",
    "\n",
    "# ⚙ Convert categorical features to numerical\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# ✂ Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# \uD83D\uDEE0 Build Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# \uD83D\uDCCA Cross-Validation to assess performance\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=2, error_score='raise')\n",
    "print(\"✅ Cross-validation scores:\", cv_scores)\n",
    "print(\"✅ Average cross-validation accuracy:\", cv_scores.mean())\n",
    "\n",
    "# \uD83D\uDD0D Hyperparameter Tuning with GridSearch\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=2, error_score='raise')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n\uD83C\uDFC6 Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"\uD83C\uDFC5 Best Cross-validation Score:\", grid_search.best_score_)\n",
    "\n",
    "# \uD83E\uDDEA Final Evaluation on Test Set\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(\"\\n\uD83D\uDCC8 Classification Report on Test Data:\\n\", classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20254b75-40de-463e-a928-4b81bb0efdb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100],\n",
    "    'classifier__max_depth': [None, 5, 10]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from grid\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adff2ab4-45a9-46d4-80a0-cf28266e5988",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f52a2154-8626-4d1f-9b71-7d3990fced22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Apex_Assessment1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}